name: Real Estate Data Scraper

on:
  schedule:
    # Runs at the start of every hour (e.g., 00:00, 01:00, etc.)
    - cron: '0 * * * *'
  workflow_dispatch:  # Still allows manual runs

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    # Checkout repository code
    - name: Checkout code
      uses: actions/checkout@v3
      
    # Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # Install dependencies
    - name: Install Python packages
      run: |
        python -m pip install --upgrade pip
        pip install selenium pandas webdriver-manager fake-useragent
        
    # Install Chrome and ChromeDriver
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
        
    # Create data directory
    - name: Create data directory
      run: mkdir -p data
        
    # Run the scraper
    - name: Run scraper
      run: python scraper.py
      
    # Commit and push results
    - name: Commit and push data
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add data/raw_data.csv
        git commit -m "Automated data update $(date +'%Y-%m-%d %H:%M')" || echo "No changes to commit"
        git push