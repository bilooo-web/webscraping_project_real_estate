name: Scrape and Clean Real Estate Data

on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  scrape-and-clean:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        persist-credentials: false  # Important for push later

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver

    - name: Install Python packages
      run: |
        python -m pip install --upgrade pip
        pip install selenium webdriver-manager pandas fake-useragent beautifulsoup4 requests

    - name: Run scraper.py
      run: python scraper.py
      
    - name: Run cleaner.py
      run: python cleaner.py
      
    - name: Commit and push changes
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add webscraping_project_real_estate/raw_data.csv cleaned_data.csv
        git diff --quiet && git diff --staged --quiet || git commit -m "Automated update: scrape and clean data"
        git push