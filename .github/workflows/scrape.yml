name: Real Estate Data Scraper and Cleaner

on:
  schedule:
    - cron: '0 * * * *'  # Runs at the start of every hour
  workflow_dispatch:     # Allows manual runs

jobs:
  scrape-and-clean:
    runs-on: ubuntu-latest
    
    steps:
    # Checkout repository code
    - name: Checkout code
      uses: actions/checkout@v3
      
    # Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # Install dependencies
    - name: Install Python packages
      run: |
        python -m pip install --upgrade pip
        pip install selenium pandas webdriver-manager fake-useragent
        
    # Install Chrome and ChromeDriver
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
        
    # Run both scripts from project folder
    - name: Run scraping and cleaning
      run: |
        cd webscraping_project_real_estate
        python scraper.py
        python cleaner.py
      
    # Commit and push all changes
    - name: Commit and push updates
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add webscraping_project_real_estate/raw_data.csv
        git add webscraping_project_real_estate/cleaned_data.csv
        git commit -m "Automated data update $(date +'%Y-%m-%d %H:%M')" || echo "No changes to commit"
        git push
